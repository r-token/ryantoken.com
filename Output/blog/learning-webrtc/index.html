<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"/><meta name="og:site_name" content="Ryan Token"/><link rel="canonical" href="https://ryantoken.com/blog/learning-webrtc"/><meta name="twitter:url" content="https://ryantoken.com/blog/learning-webrtc"/><meta name="og:url" content="https://ryantoken.com/blog/learning-webrtc"/><title>Learning WebRTC | Ryan Token</title><meta name="twitter:title" content="Learning WebRTC | Ryan Token"/><meta name="og:title" content="Learning WebRTC | Ryan Token"/><meta name="description" content="Explaining WebRTC concepts while reinforcing my own understanding."/><meta name="twitter:description" content="Explaining WebRTC concepts while reinforcing my own understanding."/><meta name="og:description" content="Explaining WebRTC concepts while reinforcing my own understanding."/><meta name="twitter:card" content="summary"/><link rel="stylesheet" href="/styles.css" type="text/css"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><link rel="shortcut icon" href="/images/favicon.png" type="image/png"/><link rel="alternate" href="/feed.rss" type="application/rss+xml" title="Subscribe to Ryan Token"/><meta name="twitter:image" content="https://ryantoken.com/favicon.ico"/><meta name="og:image" content="https://ryantoken.com/favicon.ico"/></head><body class="item-page"><header><div class="wrapper"><a class="site-name" href="/">Ryan Token</a><nav><ul><li><a href="/blog">Blog</a></li><li><a href="/about">About</a></li><li><a href="/projects">Projects</a></li><li><a href="/meta">Meta</a></li></ul></nav></div></header><div class="wrapper"><article><div class="content"><h1>Learning WebRTC</h1><p>March 07, 2021</p><p><em>Explaining WebRTC concepts while reinforcing my own understanding.</em></p><br /><hr><br /><style type="text/css">
.resizable-image img {
    text-align: center;
    margin: auto;
    width: 100%;
    border-radius: 5px;
}
</style><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-logo.png" alt="WebRTC logo"/>
</div><br /><p>WebRTC can be tricky to get wrap your mind around.</p><p>I've been working fairly heavily with the standard over the past several weeks, and wanted to document the knowledge I've gained while also demoing some sample code, examining the technology's pros and cons, and providing resources for continued learning.</p><br /><h2>First, What is WebRTC?</h2><p><a href="https://webrtc.org">WebRTC</a> stands for <strong>Web</strong> <strong>R</strong>eal-<strong>T</strong>ime <strong>C</strong>ommunication and enables "real-time communication for the web".</p><p>It has grown significantly since its initial implementation in 2011 as an open-source project by Google. Today, it's implemented as an open, standardized API that enables rich peer-to-peer communications, including audio, video, and generic data, for browsers, mobile devices, IOT devices, and more.</p><p>The most important thing WebRTC takes off of your plate is the challenge of finding the best peer-to-peer path to exchange audio and/or video in an efficient and low-latency manner.</p><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-overview.jpg" alt="WebRTC overview"/>
</div><p><em>WebRTC Overview</em></p><br /><h2>A Typical WebRTC Lifecycle</h2><ul><li>Client <em>A</em> wants to connect to Client <em>B</em></li></ul><ul><li><em>A</em> first needs to determine all possible ways that the public can connect to it (A)</li></ul><ul><li><em>B</em> then also needs to determine how the public can connect to it (B)</li></ul><ul><li><em>A</em> and <em>B</em> signal this session information (SDP) (more on this later) to each other <strong>somehow</strong>. This can be via a text, with a QR code, via HTTP, via WebSockets, or something else. The means by which you send this information doesn't matter.</li></ul><ul><li><em>A</em> then connects to <em>B</em> via the most optimal path (determined by ICE) (more on this later as well)</li></ul><ul><li><em>A</em> &amp; <em>B</em> also exchange their supported media types and security information</li></ul><ul><li>An agreement is made, and the connection is opened</li></ul><br /><h2>Necessary Concepts &amp; Terminology</h2><p><strong>NAT</strong>: Network Address Translation</p><p>To truly understand WebRTC, you have to understand at least the basics of NAT. I'll try my best at a simple explanation of NAT and why it's necessary here.</p><p>Devices don't know their public IP addresses, so NAT translates our devices' private IPs into public IPs that others can reach us at. NAT operates on the router.</p><p>Your device connects to your router's IP address, the router takes your private IP and converts it to a public IP, and that publicly accessible IP is broadcast out to the world. When others try to reach you, they ultimately reach your router's public IP and your router translates that back to your device's private IP.</p><p>There are four different NAT types: Full Cone NAT (normal NAT), Address-Restricted NAT, Port-Restricted NAT, and Symmetric NAT. All of these work well with WebRTC <em>except</em> Symmetric NAT. More info on the four NAT types <a href="https://dh2i.com/kbs/kbs-2961448-understanding-different-nat-types-and-hole-punching/">here</a>.</p><br /><p><strong>STUN Server</strong>: Session Traversal Utilities for NAT</p><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-STUN.jpg" alt="STUN server"/>
</div><p><em>A STUN Server Example</em></p><br /><p>A STUN server's main job is to tell a client what its public IP address/port is through NAT.</p><p>Talking to a STUN server is step one. We need to find <em>our</em> public presence so we can communicate that information to someone else. Once someone else has that information, we can try to communicate.</p><p>STUN servers are cheap to maintain, and many are available for you to use for free by Google and others.</p><br /><p><strong>TURN Server</strong>: Traversal Using Relays around NAT</p><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-TURN.jpg" alt="TURN server"/>
</div><p><em>A TURN Server example</em></p><br /><p>As I mentioned previously, WebRTC does not work well with Symmetric NAT. This is caused by Symmetric NAT blocking communications with the STUN server.</p><p>If a router is using Symmetric NAT, STUN won't work, and we'll have to fall back to a TURN server. This gets rid of the peer-to-peer benefit of WebRTC, and requires all communication to pass through this single TURN server, which could turn into a bottleneck with heavy usage.</p><p>If a TURN server is required, many people argue to just use a standard web server with a reverse proxy instead. Theoretically this would give you similar functionality while allowing you to have more control over the server. I haven't formed a proper opinion on this topic yet.</p><br /><p><strong>ICE</strong>: Interactive Connectivity Establishment</p><p>So we've discussed private IP addresses, public IP addresses, STUN servers, TURN servers, and more. How do we know which option is the best to connect with?</p><p>This is the primary job of ICE.</p><p>ICE collects all available candidates to use (called ICE candidates), and sends them to the remote peer via SDP.</p><br /><p><strong>SDP</strong>: Session Description Protocol</p><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-SDP.jpg" alt="SDP example"/>
</div><p><em>An SDP Example</em></p><br /><p>SDP is the most important concept in WebRTC.</p><p>Despite its name, SDP is less of a protocol and more of a <em>format</em>. It describes all ICE candidates, networking options, media options (audio/video), security options, and more, and combines it all into one massive string.</p><p>In order for another person to connect with us, we need to <strong>signal</strong> our SDP. WebRTC does not care how this is done. Once you have your SDP string, it can be signaled out via a QR code, a messaging app like WhatsApp or iMessage, via WebSockets, via HTTP, or anything else. We just need to get that large SDP string to the other party.</p><br /><h2>Revisiting the WebRTC Lifecycle</h2><p>Now that we have an understanding of the basic WebRTC concepts and terminology, let's revisit a standard WebRTC communication lifecycle with some more detail.</p><ul><li>Client <em>A</em> wants to connect to Client <em>B</em></li></ul><ul><li><em>A</em> creates an <strong>offer</strong>. The offer is just the SDP string that consists of all ICE candidates, security options, audio/video options, etc</li></ul><ul><li><em>A</em> signals that offer to <em>B</em>. Again, it doesn't matter how this signaling happens (iMessage, HTTP request, etc).</li></ul><p>(Every client has two SDP descriptions, a local SDP description and a remote SDP description)</p><ul><li>At this point, <em>A</em> has already set its own local SDP description to the offer it created in bullet 2.</li></ul><ul><li><em>B</em> now sets <em>A</em>'s <strong>offer</strong> as its remote SDP description</li></ul><ul><li><em>B</em> creates an <strong>answer</strong>, and sets that answer as its own local SDP description</li></ul><ul><li><em>B</em> signals the <strong>answer</strong> to <em>A</em>, and <em>A</em> sets <em>B</em>'s answer as <em>A</em>'s remote SDP description.</li></ul><ul><li>The connection is created, and data can flow between the two clients</li></ul><br /><h2>A Vanilla Implementation</h2><p>Let's explore how to create a basic WebRTC connection between two peers using the vanilla WebRTC implementation. No libraries or anything extra on top of it - just the basics so you really understand what's happening here. You could run this code directly in two browsers via the browsers' dev tools and it would work.</p><p><strong><em>Browser One</em></strong></p><ol><li>Create the local peer connection</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-localConnection.png" alt="WebRTC local connection code"/>
</div><br /><ol start="2"><li>Create a data channel from that connection</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-dataChannel.png" alt="WebRTC data channel code"/>
</div><br /><ol start="3"><li>Set up listeners on this channel for when a message is received (onmessage) and when a connection is opened (onopen)</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-dataChannelListeners.png" alt="WebRTC data channel listeners code"/>
</div><br /><ol start="4"><li>Set up a listener on the on the local connection for new ICE candidates. Print the SDP string every time we get a new ICE candidate. This will provide examples of what SDP strings look like.</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-onIceCandidateListener.png" alt="WebRTC ice candidate listener code"/>
</div><br /><ol start="5"><li>Create the offer locally, and set that offer as our local SDP description</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-localCreateOffer.png" alt="WebRTC local create offer code"/>
</div><br /><p><strong><em>Browser Two</em></strong></p><p>Now open a new browser window, and we'll connect the two browsers together</p><ol><li>After running the previous commands in browser one, you should have an SDP offer string printed out in your browser's dev tools. Copy and paste that from browser one, and set it to a new variable in browser two. It should look something like this:</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-offerVariable.png" alt="WebRTC offer variable code"/>
</div><br /><ol start="2"><li>Create the remote peer connection</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-remoteConnection.png" alt="WebRTC remote connection"/>
</div><br /><ol start="3"><li>Print the SDP string every time we get a new ICE candidate on the remote side this time</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-remoteOnIceCandidate.png" alt="WebRTC remote onIceCandidate listener example"/>
</div><br /><ol start="4"><li>Set up a listener on the remote connection that will receive the data channel from the other connection</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-remoteOnDataChannel.png" alt="WebRTC remote onDataChannel listener"/>
</div><br /><ol start="5"><li>Set our remote and local SDP descriptions based on the offer we received (remote SDP description) and the answer we sent (local SDP description)</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-sdpDescriptions.png" alt="WebRTC SDP descriptions code"/>
</div><br /><p><strong><em>Back to Browser One</em></strong></p><ol><li>Set the answer SDP we just generated in the previous step to an answer variable</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-answerVariable.png" alt="WebRTC answer variable code"/>
</div><br /><ol start="2"><li>We're coming full circle now. In the first section, we set the local connection's local description. In the second section, we set the remote connection's local &amp; remote descriptions. And now, we close the loop by setting the local connection's remote description to the answer we just got in the previous step. This opens the connection between the two peers.</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-setLocalRemoteDescription.png" alt="WebRTC setLocalRemoteDescription code"/>
</div><br /><ol start="3"><li>The connection is now open, and we can send data back and forth between the two browsers.</li></ol><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-dataChannelSend.png" alt="WebRTC send message code"/>
</div><br /><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-code-remoteDataChannelSend.png" alt="WebRTC remote send message code"/>
</div><br /><ol start="4"><li>You should see each those messages in the other browser's dev tools now. 👍</li></ol><br /><h2>WebRTC Pros and Cons</h2><p><strong><em>Pros</em></strong>:</p><ul><li>Having a peer-to-peer connection is fantastic. It allows for low latency and high-bandwidth content to be shared seamlessly</li></ul><ul><li>WebRTC provides a standardized way for devices to implement this functionality with an API that we don't have to build ourselves</li></ul><p><strong><em>Cons</em></strong>:</p><ul><li>Maintaining STUN and TURN servers<ul><li>STUN isn't too bad since there are free STUN servers publicly available (google maintains some for free)</li><li>TURN is expensive and more difficult, and no one offers them for free use like STUN servers</li></ul></li></ul><ul><li>Peer-to-Peer can fall apart in cases of many participants<ul><li>If you have 100 people in one environment, maintaining peer-to-peer connections between all 100 people isn't viable. This would be 99x100 connections.</li><li>A centralized server makes more sense here. Everyone connects to the centralized server, and you maintain the connection and traffic rules on that server.</li><li>More latency in this scenario, but much more viable</li><li>Large online games don't use WebRTC, for example. They use a centralized server people connect to.</li></ul></li></ul><br /><h2>Powering Up with Amazon Kinesis Video Streams</h2><p>As mentioned, one of the cons of WebRTC is the need to maintain and manage various STUN and TURN servers.</p><p><a href="https://docs.aws.amazon.com/kinesisvideostreams-webrtc-dg/latest/devguide/what-is-kvswebrtc.html">Amazon Kinesis Video Streams with WebRTC</a> offers a potential answer to this problem, as well as handling signaling for you.</p><p>In AWS's words, Amazon Kinesis Video Streams (KVS) "provides a standards-compliant WebRTC implementation as a fully managed capability. You can use Amazon Kinesis Video Streams with WebRTC to securely live stream media or perform two-way audio or video interaction between any camera IoT device and WebRTC-compliant mobile or web players. As a fully managed capability, you don't have to build, operate, or scale any WebRTC-related cloud infrastructure, such as signaling or media relay servers to securely stream media across applications and devices."</p><p>Using this service abstracts away the need to manage your own STUN and TURN servers while optimizing for even lower latency and higher bandwidth streaming.</p><p>There's a fantastic walkthrough of how to get up and running with this service <a href="https://aws.amazon.com/blogs/media/enabling-video-chats-using-amazon-kinesis-video-streams-for-webrtc/">here</a>. Familiarity with AWS isn't necessarily required to follow that video, but is certainly helpful.</p><br /><div class="resizable-image">
    <img src="../../blog_images/learning-webrtc/webrtc-kvs.png" alt="AWS KVS with WebRTC Diagram"/>
</div><p><em>AWS Kinesis Video Streams with WebRTC Architecture Diagram</em></p><br /><p>I was able to build a very performant peer-to-peer video streaming application by building on top of the aforementioned walkthrough. I recommend giving it a try and seeing how it goes for you. There's also some fantastic sample code <a href="https://github.com/awslabs/amazon-kinesis-video-streams-webrtc-sdk-js">on GitHub</a>.</p><br /><h2>Resources I Used</h2><ul><li>Getting Started with WebRTC on <a href="https://webrtc.org/getting-started/overview" target="_blank">WebRTC.org</a></li></ul><ul><li>WebRTC API on the <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API" target="_blank">Mozilla Developer Network</a></li></ul><ul><li>WebRTC Crash Course on <a href="https://www.youtube.com/watch?v=FExZvpVvYxA" target="_blank">YouTube</a><ul><li>This was particularly helpful. I highly recommend you take the time to watch the full thing.</li><li>Many of the concepts in this post were inspired directly by this video.</li></ul></li></ul><ul><li>Introduction to WebRTC on <a href="https://www.youtube.com/watch?v=NdEEp_WvnvU&t=705s" target="_blank">YouTube</a></li></ul><ul><li>What is Kinesis Video Streams with WebRTC from <a href="https://docs.aws.amazon.com/kinesisvideostreams-webrtc-dg/latest/devguide/what-is-kvswebrtc.html" target="_blank">AWS</a></li></ul><ul><li>Kinesis Video Streams with WebRTC: How it Works from <a href="https://docs.aws.amazon.com/kinesisvideostreams-webrtc-dg/latest/devguide/kvswebrtc-how-it-works.html" target="_blank">AWS</a></li></ul><ul><li>Enabling Video Chats Using Amazon Kinesis Video Streams with WebRTC from <a href="https://aws.amazon.com/blogs/media/enabling-video-chats-using-amazon-kinesis-video-streams-for-webrtc/" target="_blank">AWS</a></li></ul><ul><li>Amazon Kinesis Video Streams implementation on <a href="https://github.com/awslabs/amazon-kinesis-video-streams-webrtc-sdk-js" target="_blank">GitHub</a></li></ul><br /><h2>A Final Note</h2><p>There are a lot of YouTube videos that claim to teach you WebRTC by "building a Zoom clone" or something similar. I worked through a couple of these and found them to be less than valuable. Most layer on a bunch of third party libraries like socket.io, simple-peer, peer.js, and others to handle the dirty work.</p><p>In my opinion, it's far better to really understand the basics before lumping on these libraries.</p><br /><p><strong><a href="#">Back to Top</a></strong></p></div><span>Tagged with: </span><ul class="tag-list"><li><a href="/tags/web">Web</a></li><li><a href="/tags/webrtc">WebRTC</a></li></ul></article></div><footer><p>Built with <a href="https://www.apple.com/swift/">Swift</a> – Generated using <a href="https://github.com/johnsundell/publish">Publish</a></p><p>View my <a href="/feed.rss">RSS feed</a> – Ryan Token 2021</p><br/></footer></body></html>